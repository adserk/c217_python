{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Assignment: Text Count Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagine a vast sheet of paper on which straight Lines, Triangles, Squares, Pentagons, Hexagons, and other figures, instead of remaining fixed in their places, move freely about, on or in the surface, but without the power of rising above or sinking below it, very much like shadows - only hard and with luminous edges - and you will then have a pretty correct notion of my country and countrymen. Alas, a few years ago, I should have said \"my universe\": but now my mind has been opened to higher views of things.\n"
     ]
    }
   ],
   "source": [
    "s = \"\"\"Imagine a vast sheet of paper on which straight Lines, Triangles, Squares, Pentagons, Hexagons, and other figures, instead of remaining fixed in their places, move freely about, on or in the surface, but without the power of rising above or sinking below it, very much like shadows - only hard and with luminous edges - and you will then have a pretty correct notion of my country and countrymen. Alas, a few years ago, I should have said \"my universe\": but now my mind has been opened to higher views of things.\"\"\"\n",
    "print (s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imagine a vast sheet of paper on which straight lines, triangles, squares, pentagons, hexagons, and other figures, instead of remaining fixed in their places, move freely about, on or in the surface, but without the power of rising above or sinking below it, very much like shadows - only hard and with luminous edges - and you will then have a pretty correct notion of my country and countrymen. alas, a few years ago, i should have said \"my universe\": but now my mind has been opened to higher views of things.\n"
     ]
    }
   ],
   "source": [
    "# Step 1 \n",
    "s_lower = s.lower()\n",
    "print(s_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['imagine', 'a', 'vast', 'sheet', 'of', 'paper', 'on', 'which', 'straight', 'lines,', 'triangles,', 'squares,', 'pentagons,', 'hexagons,', 'and', 'other', 'figures,', 'instead', 'of', 'remaining', 'fixed', 'in', 'their', 'places,', 'move', 'freely', 'about,', 'on', 'or', 'in', 'the', 'surface,', 'but', 'without', 'the', 'power', 'of', 'rising', 'above', 'or', 'sinking', 'below', 'it,', 'very', 'much', 'like', 'shadows', '-', 'only', 'hard', 'and', 'with', 'luminous', 'edges', '-', 'and', 'you', 'will', 'then', 'have', 'a', 'pretty', 'correct', 'notion', 'of', 'my', 'country', 'and', 'countrymen.', 'alas,', 'a', 'few', 'years', 'ago,', 'i', 'should', 'have', 'said', '\"my', 'universe\":', 'but', 'now', 'my', 'mind', 'has', 'been', 'opened', 'to', 'higher', 'views', 'of', 'things.']\n"
     ]
    }
   ],
   "source": [
    "# Step 2\n",
    "words = str.split(s_lower)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n"
     ]
    }
   ],
   "source": [
    "# Step 3\n",
    "word_count = len(words)\n",
    "print(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'and', 'of', 'triangles,', 'which', 'correct', 'my', 'alas,', 'edges', 'lines,', 'but', 'with', 'years', 'higher', 'views', 'below', 'hexagons,', 'it,', 'has', 'their', 'straight', 'much', 'power', 'hard', '-', 'notion', 'like', 'opened', 'sinking', 'freely', 'few', 'remaining', 'in', 'imagine', 'above', 'about,', 'i', 'been', 'sheet', 'very', 'then', 'a', 'squares,', 'countrymen.', 'mind', 'said', 'country', 'to', 'have', 'other', 'pretty', 'universe\":', '\"my', 'places,', 'ago,', 'instead', 'without', 'fixed', 'move', 'shadows', 'surface,', 'pentagons,', 'will', 'only', 'things.', 'paper', 'now', 'luminous', 'should', 'vast', 'figures,', 'or', 'you', 'the', 'on', 'rising'}\n",
      "75\n"
     ]
    }
   ],
   "source": [
    "# Step 4 : Count number of distinct words using set()\n",
    "words_set = set(words)\n",
    "# The set contains only unique words\n",
    "print(words_set)\n",
    "print(len(words_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'and': 0, 'of': 0, 'triangles,': 0, 'which': 0, 'correct': 0, 'my': 0, 'alas,': 0, 'edges': 0, 'lines,': 0, 'but': 0, 'with': 0, 'years': 0, 'higher': 0, 'views': 0, 'below': 0, 'hexagons,': 0, 'it,': 0, 'has': 0, 'their': 0, 'straight': 0, 'much': 0, 'power': 0, 'hard': 0, '-': 0, 'notion': 0, 'like': 0, 'opened': 0, 'sinking': 0, 'freely': 0, 'few': 0, 'remaining': 0, 'in': 0, 'imagine': 0, 'above': 0, 'about,': 0, 'i': 0, 'been': 0, 'sheet': 0, 'very': 0, 'then': 0, 'a': 0, 'squares,': 0, 'countrymen.': 0, 'mind': 0, 'said': 0, 'country': 0, 'to': 0, 'have': 0, 'other': 0, 'pretty': 0, 'universe\":': 0, '\"my': 0, 'places,': 0, 'ago,': 0, 'instead': 0, 'without': 0, 'fixed': 0, 'move': 0, 'shadows': 0, 'surface,': 0, 'pentagons,': 0, 'will': 0, 'only': 0, 'things.': 0, 'paper': 0, 'now': 0, 'luminous': 0, 'should': 0, 'vast': 0, 'figures,': 0, 'or': 0, 'you': 0, 'the': 0, 'on': 0, 'rising': 0}\n",
      "\n",
      "\n",
      "Word Frequency:  {'and': 4, 'of': 5, 'triangles,': 1, 'which': 1, 'correct': 1, 'my': 2, 'alas,': 1, 'edges': 1, 'lines,': 1, 'but': 2, 'with': 1, 'years': 1, 'higher': 1, 'views': 1, 'below': 1, 'hexagons,': 1, 'it,': 1, 'has': 1, 'their': 1, 'straight': 1, 'much': 1, 'power': 1, 'hard': 1, '-': 2, 'notion': 1, 'like': 1, 'opened': 1, 'sinking': 1, 'freely': 1, 'few': 1, 'remaining': 1, 'in': 2, 'imagine': 1, 'above': 1, 'about,': 1, 'i': 1, 'been': 1, 'sheet': 1, 'very': 1, 'then': 1, 'a': 3, 'squares,': 1, 'countrymen.': 1, 'mind': 1, 'said': 1, 'country': 1, 'to': 1, 'have': 2, 'other': 1, 'pretty': 1, 'universe\":': 1, '\"my': 1, 'places,': 1, 'ago,': 1, 'instead': 1, 'without': 1, 'fixed': 1, 'move': 1, 'shadows': 1, 'surface,': 1, 'pentagons,': 1, 'will': 1, 'only': 1, 'things.': 1, 'paper': 1, 'now': 1, 'luminous': 1, 'should': 1, 'vast': 1, 'figures,': 1, 'or': 2, 'you': 1, 'the': 2, 'on': 2, 'rising': 1}\n"
     ]
    }
   ],
   "source": [
    "# Step 5 : The next step is to compute the frequency of the distinct words in our string.\n",
    "word_freq = dict()\n",
    "# Create a dictionary of words as key and count as value, starting with zero first\n",
    "for i in words_set:\n",
    "    word_freq[i] = 0\n",
    "print(word_freq)\n",
    "print (\"\\n\")\n",
    "# Loop through the list of words and if the word appears as a key in the dictionary append 1 to the value\n",
    "for i in words:\n",
    "    if i in word_freq:\n",
    "        word_freq[i] += 1\n",
    "print(\"Word Frequency: \", word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['imagine', 'a', 'vast', 'sheet', 'of', 'paper', 'on', 'which', 'straight', 'lines,', 'triangles,', 'squares,', 'pentagons,', 'hexagons,', 'and', 'other', 'figures,', 'instead', 'of', 'remaining', 'fixed', 'in', 'their', 'places,', 'move', 'freely', 'about,', 'on', 'or', 'in', 'the', 'surface,', 'but', 'without', 'the', 'power', 'of', 'rising', 'above', 'or', 'sinking', 'below', 'it,', 'very', 'much', 'like', 'shadows', '-', 'only', 'hard', 'and', 'with', 'luminous', 'edges', '-', 'and', 'you', 'will', 'then', 'have', 'a', 'pretty', 'correct', 'notion', 'of', 'my', 'country', 'and', 'countrymen.', 'alas,', 'a', 'few', 'years', 'ago,', 'i', 'should', 'have', 'said', '\"my', 'universe\":', 'but', 'now', 'my', 'mind', 'has', 'been', 'opened', 'to', 'higher', 'views', 'of', 'things.']\n",
      "\n",
      "\n",
      "['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~']\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Remove Punctuation Marks\n",
    "import string\n",
    "punctuation_list =  list(string.punctuation)\n",
    "\n",
    "print(words)\n",
    "print(\"\\n\")\n",
    "w_clean = list()\n",
    "print(punctuation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['imagine', 'a', 'vast', 'sheet', 'of', 'paper', 'on', 'which', 'straight', 'lines,', 'triangles,', 'squares,', 'pentagons,', 'hexagons,', 'and', 'other', 'figures,', 'instead', 'of', 'remaining', 'fixed', 'in', 'their', 'places,', 'move', 'freely', 'about,', 'on', 'or', 'in', 'the', 'surface,', 'but', 'without', 'the', 'power', 'of', 'rising', 'above', 'or', 'sinking', 'below', 'it,', 'very', 'much', 'like', 'shadows', 'only', 'hard', 'and', 'with', 'luminous', 'edges', 'and', 'you', 'will', 'then', 'have', 'a', 'pretty', 'correct', 'notion', 'of', 'my', 'country', 'and', 'countrymen.', 'alas,', 'a', 'few', 'years', 'ago,', 'i', 'should', 'have', 'said', '\"my', 'universe\":', 'but', 'now', 'my', 'mind', 'has', 'been', 'opened', 'to', 'higher', 'views', 'of', 'things.']\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "# Need to remove commas, dash, quotes and full-stop \n",
    "# compare the list of punctuations and list of words using set() to remove duplicates\n",
    "# Set removes duplicate so can't use set to compare two lists \n",
    "# Need to keep 'words' list and 'punctuation_list' as list data structure to avoid deleting duplicates\n",
    "w_clean = []\n",
    "for i in words:\n",
    "    if i not in punctuation_list:\n",
    "        w_clean.append(i)\n",
    "print(w_clean)\n",
    "print(len(w_clean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7\n",
    "Finally, create a single script that performs all of the following operations on the original 's' string.\n",
    "\n",
    "1. Convert the string to lowercase characters.\n",
    "2. Split the lowercase string into individual words.\n",
    "3. Remove the punctuation from the lowercase words. Assume that all punctuation is either the first character or the last character of each item in the list.\n",
    "4. Perform a count analysis on the words without punctuation characters.\n",
    "5. Display the dictionary with the word counts and the number of distinct words in the original string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"\"\"Imagine a vast sheet of paper on which straight Lines, Triangles, Squares, Pentagons, Hexagons, and other figures, instead of remaining fixed in their places, move freely about, on or in the surface, but without the power of rising above or sinking below it, very much like shadows - only hard and with luminous edges - and you will then have a pretty correct notion of my country and countrymen. Alas, a few years ago, I should have said \"my universe\": but now my mind has been opened to higher views of things.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Frequency:  {'imagine': 1, 'a': 3, 'vast': 1, 'sheet': 1, 'of': 5, 'paper': 1, 'on': 2, 'which': 1, 'straight': 1, 'lines,': 1, 'triangles,': 1, 'squares,': 1, 'pentagons,': 1, 'hexagons,': 1, 'and': 4, 'other': 1, 'figures,': 1, 'instead': 1, 'remaining': 1, 'fixed': 1, 'in': 2, 'their': 1, 'places,': 1, 'move': 1, 'freely': 1, 'about,': 1, 'or': 2, 'the': 2, 'surface,': 1, 'but': 2, 'without': 1, 'power': 1, 'rising': 1, 'above': 1, 'sinking': 1, 'below': 1, 'it,': 1, 'very': 1, 'much': 1, 'like': 1, 'shadows': 1, 'only': 1, 'hard': 1, 'with': 1, 'luminous': 1, 'edges': 1, 'you': 1, 'will': 1, 'then': 1, 'have': 2, 'pretty': 1, 'correct': 1, 'notion': 1, 'my': 2, 'country': 1, 'countrymen.': 1, 'alas,': 1, 'few': 1, 'years': 1, 'ago,': 1, 'i': 1, 'should': 1, 'said': 1, '\"my': 1, 'universe\":': 1, 'now': 1, 'mind': 1, 'has': 1, 'been': 1, 'opened': 1, 'to': 1, 'higher': 1, 'views': 1, 'things.': 1}\n",
      "Word Count:  90\n"
     ]
    }
   ],
   "source": [
    "s_lower = s.lower()\n",
    "words = str.split(s_lower)\n",
    "\n",
    "w_clean = []\n",
    "for i in words:\n",
    "    if i not in punctuation_list:\n",
    "        w_clean.append(i)\n",
    "\n",
    "word_freq = dict()\n",
    "# Create a dictionary of words as key and count as value, starting with zero first\n",
    "for i in w_clean:\n",
    "    word_freq[i] = 0\n",
    "\n",
    "# Loop through the list of words and if the word appears as a key in the dictionary append 1 to the value\n",
    "for i in words:\n",
    "    if i in word_freq:\n",
    "        word_freq[i] += 1\n",
    "print(\"Word Frequency: \", word_freq)\n",
    "\n",
    "word_count = len(w_clean)\n",
    "print(\"Word Count: \", word_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Count Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "# Text Count Function\n",
    "def text_count(sentence):\n",
    "    s_lower = sentence.lower()\n",
    "    words = str.split(s_lower)\n",
    "\n",
    "    w_clean = []\n",
    "    for word in words:\n",
    "        for letter in word:\n",
    "            if letter in string.punctuation:\n",
    "                word = word.replace(letter,\"\")   \n",
    "        w_clean.append(word)\n",
    "    # The remove function only removes the first occurrence of the element to remove\n",
    "    # To remove multiple instances use while loop \n",
    "    # Remove '' from the list\n",
    "    try:\n",
    "        while True:\n",
    "            w_clean.remove('')\n",
    "    except ValueError:\n",
    "        pass\n",
    "    word_freq = dict()\n",
    "# Create a dictionary of words as key and count as value, starting with zero first\n",
    "    for i in w_clean:\n",
    "        word_freq[i] = 0\n",
    "\n",
    "# Loop through the list of words and if the word appears as a key in the dictionary append 1 to the value\n",
    "    for i in w_clean:\n",
    "        if i in word_freq:\n",
    "            word_freq[i] += 1\n",
    "    print(\"Word Frequency: \", word_freq)\n",
    "\n",
    "    word_count = len(w_clean)\n",
    "    print(\"Word Count: \", word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Frequency:  {'imagine': 1, 'a': 3, 'vast': 1, 'sheet': 1, 'of': 5, 'paper': 1, 'on': 2, 'which': 1, 'straight': 1, 'lines': 1, 'triangles': 1, 'squares': 1, 'pentagons': 1, 'hexagons': 1, 'and': 4, 'other': 1, 'figures': 1, 'instead': 1, 'remaining': 1, 'fixed': 1, 'in': 2, 'their': 1, 'places': 1, 'move': 1, 'freely': 1, 'about': 1, 'or': 2, 'the': 2, 'surface': 1, 'but': 2, 'without': 1, 'power': 1, 'rising': 1, 'above': 1, 'sinking': 1, 'below': 1, 'it': 1, 'very': 1, 'much': 1, 'like': 1, 'shadows': 1, 'only': 1, 'hard': 1, 'with': 1, 'luminous': 1, 'edges': 1, 'you': 1, 'will': 1, 'then': 1, 'have': 2, 'pretty': 1, 'correct': 1, 'notion': 1, 'my': 3, 'country': 1, 'countrymen': 1, 'alas': 1, 'few': 1, 'years': 1, 'ago': 1, 'i': 1, 'should': 1, 'said': 1, 'universe': 1, 'now': 1, 'mind': 1, 'has': 1, 'been': 1, 'opened': 1, 'to': 1, 'higher': 1, 'views': 1, 'things': 1}\n",
      "Word Count:  90\n"
     ]
    }
   ],
   "source": [
    "s = \"\"\"Imagine a vast sheet of paper on which straight Lines, Triangles, Squares, Pentagons, Hexagons, and other figures, instead of remaining fixed in their places, move freely about, on or in the surface, but without the power of rising above or sinking below it, very much like shadows - only hard and with luminous edges - and you will then have a pretty correct notion of my country and countrymen. Alas, a few years ago, I should have said \"my universe\": but now my mind has been opened to higher views of things.\"\"\"\n",
    "text_count(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Frequency:  {'cant': 1, 'imagine': 1, 'a': 1, 'vast': 1, 'sheet': 1, 'of': 1, 'paper': 1, 'on': 1, 'which': 1, 'straight': 1, 'lines': 1, 'triangles': 1, 'squares': 1, 'pentagons': 1, 'hexagons': 1, 'and': 1, 'other': 1, 'figures': 1}\n",
      "Word Count:  18\n"
     ]
    }
   ],
   "source": [
    "# this removes every punctuations but things like \"can't\" become \"cant\"\n",
    "s = \"Can't imagine a vast sheet of paper on which straight Lines, Triangles, Squares, Pentagons, Hexagons, and other figures\"\n",
    "new_s = (s.translate(str.maketrans('', '', string.punctuation)))\n",
    "text_count(new_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['imagine', 'a', 'vast', 'sheet', 'of', 'paper', 'on', 'which', 'straight', 'lines,', 'triangles,', 'squares,', 'pentagons,', 'hexagons,', 'and', 'other', 'figures,', 'instead', 'of', 'remaining', 'fixed', 'in', 'their', 'places,', 'move', 'freely', 'about,', 'on', 'or', 'in', 'the', 'surface,', 'but', 'without', 'the', 'power', 'of', 'rising', 'above', 'or', 'sinking', 'below', 'it,', 'very', 'much', 'like', 'shadows', 'only', 'hard', 'and', 'with', 'luminous', 'edges', 'and', 'you', 'will', 'then', 'have', 'a', 'pretty', 'correct', 'notion', 'of', 'my', 'country', 'and', 'countrymen.', 'alas,', 'a', 'few', 'years', 'ago,', 'i', 'should', 'have', 'said', '\"my', 'universe\":', 'but', 'now', 'my', 'mind', 'has', 'been', 'opened', 'to', 'higher', 'views', 'of', 'things.']\n"
     ]
    }
   ],
   "source": [
    "s_lower = s.lower()\n",
    "words = str.split(s_lower)\n",
    "\n",
    "w_clean = []\n",
    "for i in words:\n",
    "    if i not in punctuation_list:\n",
    "        w_clean.append(i)\n",
    "\n",
    "print(w_clean)\n",
    "\n",
    "\n",
    "# word_freq = dict()\n",
    "# # Create a dictionary of words as key and count as value, starting with zero first\n",
    "# for i in w_clean:\n",
    "#     word_freq[i] = 0\n",
    "\n",
    "# # Loop through the list of words and if the word appears as a key in the dictionary append 1 to the value\n",
    "# for i in words:\n",
    "#     if i in word_freq:\n",
    "#         word_freq[i] += 1\n",
    "# print(\"Word Frequency: \", word_freq)\n",
    "\n",
    "# word_count = len(w_clean)\n",
    "# print(\"Word Count: \", word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'universe:'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "test = 'universe\":'\n",
    "\n",
    "pattern = '\"'\n",
    "re.sub(pattern, \"\", test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['imagine', 'a', 'vast', 'sheet', 'of', 'paper', 'on', 'which', 'straight', 'lines,', 'triangles,', 'squares,', 'pentagons,', 'hexagons,', 'and', 'other', 'figures,', 'instead', 'of', 'remaining', 'fixed', 'in', 'their', 'places,', 'move', 'freely', 'about,', 'on', 'or', 'in', 'the', 'surface,', 'but', 'without', 'the', 'power', 'of', 'rising', 'above', 'or', 'sinking', 'below', 'it,', 'very', 'much', 'like', 'shadows', 'only', 'hard', 'and', 'with', 'luminous', 'edges', 'and', 'you', 'will', 'then', 'have', 'a', 'pretty', 'correct', 'notion', 'of', 'my', 'country', 'and', 'countrymen.', 'alas,', 'a', 'few', 'years', 'ago,', 'i', 'should', 'have', 'said', 'my', 'universe', 'but', 'now', 'my', 'mind', 'has', 'been', 'opened', 'to', 'higher', 'views', 'of', 'things.']\n"
     ]
    }
   ],
   "source": [
    "w_clean_new = []\n",
    "for i in w_clean:\n",
    "    pattern = '\"'\n",
    "    k = re.sub(pattern, \"\", i)\n",
    "    pattern2 = ':'\n",
    "    n = re.sub(pattern2, \"\", k)\n",
    "    w_clean_new.append(n)\n",
    "print(w_clean_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lines,\n",
      "triangles,\n",
      "squares,\n",
      "pentagons,\n",
      "hexagons,\n",
      "figures,\n",
      "places,\n",
      "about,\n",
      "surface,\n",
      "it,\n",
      "countrymen.\n",
      "alas,\n",
      "ago,\n",
      "\"my\n",
      "universe\":\n",
      "universe\":\n",
      "things.\n",
      "['lines', 'triangles', 'squares', 'pentagons', 'hexagons', 'figures', 'places', 'about', 'surface', 'it', '', 'alas', 'ago', 'my', 'universe:', 'universe\"', '']\n"
     ]
    }
   ],
   "source": [
    "removed = []\n",
    "for item in w_clean:\n",
    "    n = len(punctuation_list)\n",
    "    for i in range(n):\n",
    "        if punctuation_list[i] in item:\n",
    "            print(item)\n",
    "            pattern = punctuation_list[i]\n",
    "            k = re.sub(pattern, \"\", item)\n",
    "            removed.append(k)\n",
    "print(removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['imagine', 'a', 'vast', 'sheet', 'of', 'paper', 'on', 'which', 'straight', 'lines', 'triangles', 'squares', 'pentagons', 'hexagons', 'and', 'other', 'figures', 'instead', 'of', 'remaining', 'fixed', 'in', 'their', 'places', 'move', 'freely', 'about', 'on', 'or', 'in', 'the', 'surface', 'but', 'without', 'the', 'power', 'of', 'rising', 'above', 'or', 'sinking', 'below', 'it', 'very', 'much', 'like', 'shadows', 'only', 'hard', 'and', 'with', 'luminous', 'edges', 'and', 'you', 'will', 'then', 'have', 'a', 'pretty', 'correct', 'notion', 'of', 'my', 'country', 'and', 'countrymen', 'alas', 'a', 'few', 'years', 'ago', 'i', 'should', 'have', 'said', 'my', 'universe', 'but', 'now', 'my', 'mind', 'has', 'been', 'opened', 'to', 'higher', 'views', 'of', 'things']\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "new_words = []\n",
    "for word in w_clean:\n",
    "    for letter in word:\n",
    "        if letter in string.punctuation:\n",
    "            word = word.replace(letter,\"\")   \n",
    "    new_words.append(word)\n",
    "\n",
    "print(new_words)\n",
    "print(len(new_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a8822641e88d7c74114f38a155dc8686f9f41cc7c790ba54cfc07cc82201c3e7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
